
Assumption is a pre-setup instance with Python 3 and Ansible installed server, and the server could a pre-defined ami, reason being:
1. All the setup done in the same VPC
2. No need to transfer private key elsewhere
3. The usage of ElasticSearch is for REST API
4. The server running ElasticSearch is type t2.small due to minimum RAM requirement(2GB)


1. What did you choose to automate the provisioning and bootstrapping of the instance? Why?
- Automated infra provisioning using Terraform:
    - VPC network with public/private subnet
    - Internet Gateway
    - NAT instance (In freetier)
        - Bastion server/Ansible are running on this server for demo setup
    - EC2 instance to run ElasticSearch in private subnet

- Automated server configurations via Ansible:
    - Common setup, e.g. log agent
    - Java
    - ElasticSearch

2. How did you choose to secure ElasticSearch? Why?
- The server runs ElasticSearch is put in private subnet so it doesn't recieve any access directly from external
- Setup a Nginx proxy to guard all the server access to ElasticSearch and hide the default port 9200 from external
- Config basic authentication to access ElasticSearch

3. How would you monitor this instance? What metrics would you monitor?
- Use CloudWatch as the default monitor service
- Use 3rd party montior agent like DynaTrace/Nagios for advanced monitor
- Basic metrics CPU, disk I/O, disk space and
- Advanced metrics: memory usage, JVM health depends on the monitor tool used
- Create alerts if the metrics burst certain threshold, and the reaction can be autoscale, email to ops and etc.


4. Could you extend your solution to launch a secure cluster of ElasticSearch nodes? What
would need to change to support this use case?
- I need to take sometime and research but I know it's possible to create ElasticSearch clusters

5. Could you extend your solution to replace a running ElasticSearch instance with little or no
downtime? How?
6. Was it a priority to make your code well structured, extensible, and reusable?
- Use a structured Terraform pre-configurations, which use all module-based setup, so that all the
 modules are separated, e.g. network, compute resources and etc.
 All the major variables are extracted into terraform.tfvars and running in a different component(main.tf),
 it is a flexiable setup catering to different environment, e.g. DEV, PROD, which the major modules stay unchanged
- Use a structured Ansible pre-configurations, which allows different setup for different ENV.
  The setup also support multiple cloud
- In Ansible setup, all the applications are separated by different roles, so that all different servers
  come in with a combination of different roles

7. What sacrifices did you make due to time?
- There is no Load Balancer configured
- ElasticSearch cluster was not ready
- SSL setup is not done for Nginx proxy